{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "134c5ae3-9bf7-4714-9f86-f8485e5d51fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Model Compression in PyTorch\n",
    "import torch\n",
    "from torchvision import models\n",
    "\n",
    "# Rebuild your model\n",
    "model = models.mobilenet_v2(pretrained=False)\n",
    "model.classifier[1] = torch.nn.Linear(model.last_channel, 2)\n",
    "model.load_state_dict(torch.load('model_updated_2.pth'))\n",
    "model.eval()\n",
    "\n",
    "dummy_input = torch.randn(1, 3, 128, 128)\n",
    "\n",
    "torch.onnx.export(model, dummy_input, \"model_updated_2.onnx\",\n",
    "                  input_names=['input'], output_names=['output'],\n",
    "                  dynamic_axes={'input': {0: 'batch_size'}, 'output': {0: 'batch_size'}},\n",
    "                  opset_version=11)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd3ffdc6-0530-4d88-8c1d-598b9d742533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\anaconda3\\envs\\stylegan2-py38\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f931bf6-5421-4cce-b988-d4db9e77ef7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is valid.\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Check ONNX Model\n",
    "import onnx\n",
    "\n",
    "onnx_model = onnx.load(\"model.onnx\")\n",
    "onnx.checker.check_model(onnx_model)\n",
    "print(\"Model is valid.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cce1ba5a-98bd-4421-a653-2db1ba24ee1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Please consider to run pre-processing before quantization. Refer to example: https://github.com/microsoft/onnxruntime-inference-examples/blob/main/quantization/image_classification/cpu/ReadMe.md \n"
     ]
    }
   ],
   "source": [
    "from onnxruntime.quantization import quantize_dynamic, QuantType\n",
    "\n",
    "quantize_dynamic('model.onnx', 'model_quantized.onnx', weight_type=QuantType.QInt8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ee880fb-ceba-4587-9db0-ce062c537435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX graph optimization completed.\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "import onnxoptimizer\n",
    "\n",
    "model = onnx.load('model_quantized.onnx')\n",
    "\n",
    "# Basic optimization passes\n",
    "passes = [\"eliminate_nop_transpose\", \"eliminate_deadend\"]\n",
    "\n",
    "optimized_model = onnxoptimizer.optimize(model, passes)\n",
    "\n",
    "onnx.save(optimized_model, 'model_quantized_optimized.onnx')\n",
    "\n",
    "print(\"ONNX graph optimization completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf24cec4-40cd-4a55-9e4e-5c78ad5c237f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Model Compression in PyTorch\n",
    "import torch\n",
    "from torchvision import models\n",
    "\n",
    "# Rebuild your model\n",
    "model = models.mobilenet_v2(pretrained=False)\n",
    "model.classifier[1] = torch.nn.Linear(model.last_channel, 2)\n",
    "model.load_state_dict(torch.load('model_updated.pth'))\n",
    "model.eval()\n",
    "\n",
    "dummy_input = torch.randn(1, 3, 128, 128)\n",
    "\n",
    "torch.onnx.export(model, dummy_input, \"model_updated.onnx\",\n",
    "                  input_names=['input'], output_names=['output'],\n",
    "                  dynamic_axes={'input': {0: 'batch_size'}, 'output': {0: 'batch_size'}},\n",
    "                  opset_version=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4beb046c-ca14-421e-ab64-a58ed10bb284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Model Compression in PyTorch\n",
    "import torch\n",
    "from torchvision import models\n",
    "\n",
    "# Rebuild your model\n",
    "model = models.mobilenet_v2(pretrained=False)\n",
    "model.classifier[1] = torch.nn.Linear(model.last_channel, 2)\n",
    "model.load_state_dict(torch.load('model_updated_1.pth'))\n",
    "model.eval()\n",
    "\n",
    "dummy_input = torch.randn(1, 3, 128, 128)\n",
    "\n",
    "torch.onnx.export(model, dummy_input, \"model_updated1.onnx\",\n",
    "                  input_names=['input'], output_names=['output'],\n",
    "                  dynamic_axes={'input': {0: 'batch_size'}, 'output': {0: 'batch_size'}},\n",
    "                  opset_version=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d77b20-663f-4716-a0eb-35491f809a4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (StyleGAN2)",
   "language": "python",
   "name": "stylegan2-py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
